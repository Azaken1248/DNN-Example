{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "51cd5ab9",
      "metadata": {
        "id": "51cd5ab9"
      },
      "source": [
        "# CNN implementation on Dementia Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c1af04a8",
      "metadata": {
        "id": "c1af04a8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2 as cv\n",
        "import os, sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "a821ed6a",
      "metadata": {
        "id": "a821ed6a"
      },
      "outputs": [],
      "source": [
        "path1='/content/drive/MyDrive/Alzheimer Dataset/NonDemented'\n",
        "path2='/content/drive/MyDrive/Alzheimer Dataset/MildDemented'\n",
        "path3='//content/drive/MyDrive/Alzheimer Dataset/ModerateDemented'\n",
        "files1=os.listdir(path1)\n",
        "files2=os.listdir(path2)\n",
        "files3=os.listdir(path3)\n",
        "Num_files_N=len(files1)\n",
        "Num_files_MD=len(files2)\n",
        "Num_files_D=len(files3)\n",
        "dataset_len=Num_files_N+Num_files_MD+Num_files_D"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(files3)\n"
      ],
      "metadata": {
        "id": "QT0gHQYA4K18"
      },
      "id": "QT0gHQYA4K18",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "29252846",
      "metadata": {
        "id": "29252846"
      },
      "source": [
        "# Dataset Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7cdb862",
      "metadata": {
        "id": "f7cdb862"
      },
      "source": [
        "For every file\n",
        "\n",
        "1. Read the image\n",
        "2. Convert it to grayscale (Optional)\n",
        "3. Resize to (100,100)\n",
        "4. Preprocessing: Normalization\n",
        "5. Reshape to (100,100,1)\n",
        "6. Create the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ead1101",
      "metadata": {
        "collapsed": true,
        "id": "2ead1101"
      },
      "outputs": [],
      "source": [
        "data=np.zeros((dataset_len,100,100,1))\n",
        "label=[]\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "24314cc2",
      "metadata": {
        "id": "24314cc2"
      },
      "outputs": [],
      "source": [
        "for i in range(Num_files_N):\n",
        "    name=path1+'/'+files1[i]\n",
        "    img=cv.imread(name)\n",
        "    img_gs=cv.cvtColor(img,cv.COLOR_RGB2GRAY)\n",
        "    img_gs=cv.resize(img_gs,(100,100))\n",
        "    img_gs=img_gs/255\n",
        "    img_gs=img_gs.reshape(100,100,1)\n",
        "    data[i,:,:]=img_gs\n",
        "    label.append('Normal')\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b5ac2af",
      "metadata": {
        "collapsed": true,
        "id": "6b5ac2af"
      },
      "outputs": [],
      "source": [
        "plt.imshow(data[99],cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b32b0be4",
      "metadata": {
        "collapsed": true,
        "id": "b32b0be4",
        "outputId": "13b22b88-4ffd-414a-ba86-4773800daf57"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x205527dea30>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(data[100],cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(Num_files_MD):\n",
        "    name=path2+'/'+files2[i]\n",
        "    img=cv.imread(name)\n",
        "    img_gs=cv.cvtColor(img,cv.COLOR_RGB2GRAY)\n",
        "    img_gs=cv.resize(img_gs,(100,100))\n",
        "    img_gs=img_gs/255\n",
        "    img_gs=img_gs.reshape(100,100,1)\n",
        "    data[i+Num_files_N,:,:]=img_gs\n",
        "    label.append('Mild Dementia')"
      ],
      "metadata": {
        "id": "YhCjXaqDxY6n"
      },
      "id": "YhCjXaqDxY6n",
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "b9df95c2",
      "metadata": {
        "id": "b9df95c2"
      },
      "outputs": [],
      "source": [
        "for i in range(Num_files_D):\n",
        "    name=path3+'/'+files3[i]\n",
        "    img=cv.imread(name)\n",
        "    img_gs=cv.cvtColor(img,cv.COLOR_RGB2GRAY)\n",
        "    img_gs=cv.resize(img_gs,(100,100))\n",
        "    img_gs=img_gs/255\n",
        "    img_gs=img_gs.reshape(100,100,1)\n",
        "    data[i+Num_files_N+Num_files_MD,:,:]=img_gs\n",
        "    label.append('Dementia')\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04c95186",
      "metadata": {
        "collapsed": true,
        "id": "04c95186"
      },
      "outputs": [],
      "source": [
        "plt.imshow(data[100],cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0ee2e56",
      "metadata": {
        "id": "a0ee2e56"
      },
      "source": [
        "Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "ab8c94e7",
      "metadata": {
        "id": "ab8c94e7"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le=LabelEncoder()\n",
        "lab=le.fit_transform(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2869770e",
      "metadata": {
        "collapsed": true,
        "id": "2869770e"
      },
      "outputs": [],
      "source": [
        "label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1af2bd04",
      "metadata": {
        "collapsed": true,
        "id": "1af2bd04"
      },
      "outputs": [],
      "source": [
        "lab"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3536af9f",
      "metadata": {
        "id": "3536af9f"
      },
      "source": [
        "Train and test dataset spilt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "0e55f94c",
      "metadata": {
        "id": "0e55f94c"
      },
      "outputs": [],
      "source": [
        "train_images,test_images,train_labels,test_labels=train_test_split(data,lab,test_size=0.2,random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "001342f9",
      "metadata": {
        "id": "001342f9"
      },
      "outputs": [],
      "source": [
        "print('Train Dataset Size:',np.size(train_labels))\n",
        "print('Test Dataset Size:',np.size(test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33a6d409",
      "metadata": {
        "id": "33a6d409"
      },
      "source": [
        "# Define the CNN architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73ab126f",
      "metadata": {
        "id": "73ab126f"
      },
      "source": [
        "Create the convolutional base\n",
        "\n",
        "1. Convolutional : 32 filters 3x3\n",
        "2. Maxpooling: 2x2\n",
        "3. Convolutional : 64 filters 5x5\n",
        "4. Convolutional : 32 filters 3x3\n",
        "5. Maxpooling: 3x3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "01322894",
      "metadata": {
        "id": "01322894"
      },
      "outputs": [],
      "source": [
        "network=models.Sequential()\n",
        "network.add(layers.Conv2D(32,(3,3),activation='relu', input_shape=(100,100,1)))\n",
        "network.add(layers.MaxPooling2D((2,2)))\n",
        "network.add(layers.Conv2D(64,(7,7),activation='relu'))\n",
        "network.add(layers.Conv2D(32,(3,3),activation='relu'))\n",
        "network.add(layers.MaxPooling2D((3,3)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fa63e7a",
      "metadata": {
        "id": "0fa63e7a"
      },
      "source": [
        "Check summary of convolutional base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e8ac882",
      "metadata": {
        "id": "0e8ac882"
      },
      "outputs": [],
      "source": [
        "network.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e49eab1",
      "metadata": {
        "id": "7e49eab1"
      },
      "source": [
        "Build the classifier on top of the convolutional base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "99a58d24",
      "metadata": {
        "id": "99a58d24"
      },
      "outputs": [],
      "source": [
        "network.add(layers.Flatten())\n",
        "network.add(layers.Dense(80,activation='relu'))\n",
        "network.add(layers.Dense(50,activation='relu'))\n",
        "network.add(layers.Dense(3,activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f7ba93f",
      "metadata": {
        "collapsed": true,
        "id": "7f7ba93f"
      },
      "outputs": [],
      "source": [
        "network.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf809688",
      "metadata": {
        "id": "bf809688"
      },
      "source": [
        "Compile and train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "226df6b8",
      "metadata": {
        "id": "226df6b8"
      },
      "outputs": [],
      "source": [
        "network.compile(optimizer='sgd',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels"
      ],
      "metadata": {
        "id": "BVTL71MYyeFe"
      },
      "id": "BVTL71MYyeFe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a02dcf5a",
      "metadata": {
        "id": "a02dcf5a"
      },
      "outputs": [],
      "source": [
        "trained_network=network.fit(train_images,train_labels,epochs=10,validation_data=(test_images,test_labels))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels.shape"
      ],
      "metadata": {
        "id": "Sx-oC71U5gNA"
      },
      "id": "Sx-oC71U5gNA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5039efe",
      "metadata": {
        "id": "e5039efe"
      },
      "outputs": [],
      "source": [
        "plt.plot(trained_network.history['accuracy'],label='Training Accuracy')\n",
        "plt.plot(trained_network.history['val_accuracy'],label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0,1.1])\n",
        "plt.legend(loc='lower right')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44db3a23",
      "metadata": {
        "id": "44db3a23"
      },
      "outputs": [],
      "source": [
        "plt.plot(trained_network.history['loss'],label='Training Loss')\n",
        "plt.plot(trained_network.history['val_loss'],label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper right')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "656e1c17",
      "metadata": {
        "id": "656e1c17"
      },
      "source": [
        "Evaluate the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2476b8e5",
      "metadata": {
        "collapsed": true,
        "id": "2476b8e5"
      },
      "outputs": [],
      "source": [
        "test_loss,test_acc=network.evaluate(test_images,test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa6cec7b",
      "metadata": {
        "id": "aa6cec7b"
      },
      "outputs": [],
      "source": [
        "y_predict=network.predict(test_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "cb5ef5da",
      "metadata": {
        "id": "cb5ef5da"
      },
      "outputs": [],
      "source": [
        "y_pred=[]\n",
        "for val in y_predict:\n",
        "    y_pred.append(np.argmax(val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51b9d88d",
      "metadata": {
        "id": "51b9d88d"
      },
      "outputs": [],
      "source": [
        "print(metrics.confusion_matrix(test_labels,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cce68d11",
      "metadata": {
        "scrolled": true,
        "id": "cce68d11"
      },
      "outputs": [],
      "source": [
        "print(metrics.accuracy_score(test_labels,y_pred))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}